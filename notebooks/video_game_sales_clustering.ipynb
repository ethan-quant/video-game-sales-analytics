{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33fde8ab",
   "metadata": {
    "id": "33fde8ab"
   },
   "source": [
    "# ðŸŽ® Video Game Sales Analytics (Clustering + PCA)\n",
    "\n",
    "**Objective:** Analyze global video game sales data to identify **regional demand patterns** using clustering and visualization.\n",
    "\n",
    "**How to run:**\n",
    "1. Place `vgsales.csv` in `data/` (or update `CSV_PATH`).\n",
    "2. Run cells top-to-bottom.\n",
    "\n",
    "> Note: This notebook is a cleaned, portfolio-ready version of an MBA data analytics project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f42fa4",
   "metadata": {
    "id": "c7f42fa4"
   },
   "source": [
    "\n",
    "## 1) Setup\n",
    "\n",
    "- If running in **Google Colab**, upload `vgsales.csv` to the session or mount Drive and set the path accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a174c15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a174c15",
    "outputId": "c410aa23-d0e6-4d70-b345-dd3aa8c5cc50"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print(\"Libraries imported.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed792512",
   "metadata": {
    "id": "ed792512"
   },
   "source": [
    "\n",
    "## 2) Load Dataset\n",
    "- Replace the path if needed. If using Colab, either upload the CSV and use `/content/vgsales.csv` or point to your Drive path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66df92c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "d66df92c",
    "outputId": "f1e1d5fe-cf56-4402-ccdf-c97da89f6eb6"
   },
   "outputs": [],
   "source": [
    "\n",
    "CSV_PATH = 'data/vgsales.csv'  # update if your file is elsewhere  # change if needed\n",
    "\n",
    "# Load\n",
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(df_raw.shape)\n",
    "df_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c9354",
   "metadata": {
    "id": "267c9354"
   },
   "source": [
    "\n",
    "## 3) Data Overview & Quality Checks\n",
    "- Show columns, dtypes, missing values, and duplicates.\n",
    "- Decide which columns to keep (we're **excluding `Year`**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e533cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76e533cc",
    "outputId": "bb3cb30f-a17c-47b7-ea50-e219dae362cd"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Columns:\", list(df_raw.columns))\n",
    "print(\"\\nDtypes:\\n\", df_raw.dtypes)\n",
    "print(\"\\nMissing values per column:\\n\", df_raw.isna().sum())\n",
    "print(\"\\nDuplicate rows:\", df_raw.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace38d5f",
   "metadata": {
    "id": "ace38d5f"
   },
   "source": [
    "\n",
    "## 4) Data Cleaning (without `Year`)\n",
    "**Cleaning decisions:**\n",
    "- Drop low-value/identifier columns: `Rank`\n",
    "- **Exclude `Year`** per your project decision\n",
    "- Trim whitespace from text columns\n",
    "- Drop exact duplicates on key identifiers\n",
    "- Handle missing values (drop where essential features are missing)\n",
    "- Ensure sales columns are numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804e8a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "f804e8a0",
    "outputId": "b7fadf90-d37c-4439-d4ce-e480bef5a3e8"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# 1) Drop columns (ignore if not present)\n",
    "df.drop(columns=['Rank', 'Year'], errors='ignore', inplace=True)\n",
    "\n",
    "# 2) Strip whitespace in column names & string cells\n",
    "df.columns = df.columns.str.strip()\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# 3) Coerce sales columns to numeric (safe-guard)\n",
    "sales_cols = [c for c in df.columns if c.endswith('_Sales') or c.lower() == 'global_sales']\n",
    "for c in sales_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# 4) Drop duplicates based on key identifiers (tune if needed)\n",
    "key_cols = [c for c in ['Name','Platform','Genre','Publisher'] if c in df.columns]\n",
    "if key_cols:\n",
    "    before = df.shape[0]\n",
    "    df = df.drop_duplicates(subset=key_cols)\n",
    "    print(f\"Removed {before - df.shape[0]} duplicate rows based on {key_cols}.\")\n",
    "\n",
    "# 5) Handle missing values: drop rows missing essential fields\n",
    "essential = [c for c in ['Name','Platform','Genre','Publisher','Global_Sales'] if c in df.columns]\n",
    "df = df.dropna(subset=essential)\n",
    "\n",
    "# 6) Confirm Global_Sales exists; if not, create from regionals\n",
    "if 'Global_Sales' not in df.columns:\n",
    "    regionals = [c for c in ['NA_Sales','EU_Sales','JP_Sales','Other_Sales'] if c in df.columns]\n",
    "    if regionals:\n",
    "        df['Global_Sales'] = df[regionals].sum(axis=1)\n",
    "\n",
    "print(\"Shape after cleaning:\", df.shape)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9426262c",
   "metadata": {
    "id": "9426262c"
   },
   "source": [
    "\n",
    "## 5) Exploratory Data Analysis (EDA)\n",
    "Focus on **genres**, **platforms**, and **titles** without using `Year`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d422e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d61d422e",
    "outputId": "2950b7f7-2e1c-4e00-8438-82ff500defb7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- EDA: Global Sales by Genre, Platform, and Top 10 Games ---\n",
    "\n",
    "def barplot_series(s, title, xlabel=None, ylabel=None, top=None, rotation=45):\n",
    "    if top:\n",
    "        s = s.head(top)\n",
    "    plt.figure()\n",
    "    s.plot(kind='bar')\n",
    "    plt.xticks(rotation=rotation, ha='right')\n",
    "    if title: plt.title(title)\n",
    "    if xlabel: plt.xlabel(xlabel)\n",
    "    if ylabel: plt.ylabel(ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Global sales by Genre\n",
    "if 'Genre' in df.columns and 'Global_Sales' in df.columns:\n",
    "    genre_sales = df.groupby('Genre')['Global_Sales'].sum().sort_values(ascending=False)\n",
    "    barplot_series(genre_sales, \"Global Sales by Genre\", ylabel=\"Sales (Millions)\")\n",
    "\n",
    "# Global sales by Platform (top 12)\n",
    "if 'Platform' in df.columns and 'Global_Sales' in df.columns:\n",
    "    platform_sales = df.groupby('Platform')['Global_Sales'].sum().sort_values(ascending=False)\n",
    "    barplot_series(platform_sales, \"Global Sales by Platform (Top 12)\", ylabel=\"Sales (Millions)\", top=12)\n",
    "\n",
    "# Top 10 best-selling games overall (ranked 1â€“10)\n",
    "cols = [c for c in ['Name','Platform','Genre','Publisher','Global_Sales'] if c in df.columns]\n",
    "top10 = (\n",
    "    df.sort_values('Global_Sales', ascending=False)\n",
    "      .head(10)[cols]\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "top10.index = top10.index + 1   # shifts index from 0â€“9 to 1â€“10\n",
    "top10.index.name = \"Rank\"\n",
    "display(top10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93734efa",
   "metadata": {
    "id": "93734efa"
   },
   "source": [
    "## 6) K-Means Clustering on Regional Sales\n",
    "\n",
    "**Goal:** Identify clusters of games based on their regional sales patterns  \n",
    "(`NA_Sales`, `EU_Sales`, `JP_Sales`, `Other_Sales`).\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Use the **Elbow Method** to choose the number of clusters (k).  \n",
    "2. Fit a K-Means model on regional sales.  \n",
    "3. Summarize each cluster with **average sales per region**.  \n",
    "4. Visualize clusters using:\n",
    "   - A **heatmap** of average sales by cluster and region  \n",
    "   - A **radar (spider) chart** of regional profiles  \n",
    "   - A **bar chart** comparing regions across clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rW8uUrsQatGR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "rW8uUrsQatGR",
    "outputId": "68f5ebbb-d2f7-428b-e1a6-e80b329f0227"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Columns we use for clustering\n",
    "regional_cols = [\"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\"]\n",
    "\n",
    "# Feature matrix (fill missing with 0 just in case)\n",
    "X = df[regional_cols].fillna(0.0).values\n",
    "\n",
    "# Scale features for K-Means\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# -----------------------\n",
    "# Elbow Method to choose k\n",
    "# -----------------------\n",
    "inertias = []\n",
    "K = range(2, 10)\n",
    "\n",
    "for k in K:\n",
    "    km_tmp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km_tmp.fit(X_scaled)\n",
    "    inertias.append(km_tmp.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(list(K), inertias, marker=\"o\")\n",
    "plt.title(\"Elbow Method: Choose k\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia (Within-Cluster SSE)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# Fit final K-Means (k=3 from elbow plot)\n",
    "# -----------------------\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "df[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Cluster sizes\n",
    "print(\"=== Cluster Sizes ===\")\n",
    "print(df[\"Cluster\"].value_counts().sort_index(), \"\\n\")\n",
    "\n",
    "# Cluster profile: mean sales per region\n",
    "cluster_means = (\n",
    "    df.groupby(\"Cluster\")[regional_cols]\n",
    "      .mean()\n",
    "      .round(2)\n",
    ")\n",
    "\n",
    "cluster_means[\"Total_Titles\"] = df[\"Cluster\"].value_counts().sort_index()\n",
    "print(\"=== Cluster Profile (Average Sales per Region, in millions) ===\")\n",
    "display(cluster_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2C5v0UQHauBH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2C5v0UQHauBH",
    "outputId": "ac6c8ead-39b3-408d-ce3d-00428033161e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We will reuse cluster_means and regional_cols from the previous cell\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1) HEATMAP: Average Regional Sales by Cluster\n",
    "# -------------------------------------------------------\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.imshow(cluster_means[regional_cols], aspect=\"auto\")\n",
    "plt.colorbar(label=\"Average Sales (millions)\")\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(regional_cols)),\n",
    "    labels=regional_cols\n",
    ")\n",
    "plt.yticks(\n",
    "    ticks=np.arange(len(cluster_means)),\n",
    "    labels=[f\"Cluster {i}\" for i in cluster_means.index]\n",
    ")\n",
    "plt.title(\"Heatmap: Average Regional Sales by Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2) RADAR / SPIDER CHART: Regional Profile by Cluster\n",
    "# -------------------------------------------------------\n",
    "regions = regional_cols\n",
    "angles = np.linspace(0, 2*np.pi, len(regions), endpoint=False).tolist()\n",
    "angles += angles[:1]  # close the circle\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "for i, (idx, row) in enumerate(cluster_means[regional_cols].iterrows()):\n",
    "    values = row.tolist()\n",
    "    values += values[:1]\n",
    "    plt.polar(angles, values, linewidth=2, label=f\"Cluster {idx}\")\n",
    "\n",
    "# Improve spacing to avoid overlap\n",
    "plt.xticks(angles[:-1], regions, fontsize=12)\n",
    "\n",
    "# Move title upward\n",
    "plt.title(\n",
    "    \"Radar Chart: Regional Sales Profile by Cluster\",\n",
    "    y=1.12,                 # moves title higher\n",
    "    fontsize=14\n",
    ")\n",
    "\n",
    "# Optional tweak: rotate the top label slightly (EU_Sales)\n",
    "labels = plt.gca().get_xticklabels()\n",
    "labels[1].set_rotation(10)  # adjust angle if needed\n",
    "\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.3, 1.1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3) BAR CHART: Average Regional Sales per Cluster\n",
    "# -------------------------------------------------------\n",
    "plt.figure(figsize=(8,5))\n",
    "x = np.arange(len(cluster_means.index))  # positions for clusters\n",
    "width = 0.2\n",
    "\n",
    "for i, region in enumerate(regional_cols):\n",
    "    plt.bar(\n",
    "        x + i*width,\n",
    "        cluster_means[region].values,\n",
    "        width=width,\n",
    "        label=region\n",
    "    )\n",
    "\n",
    "plt.xticks(x + width * (len(regional_cols)-1) / 2, [f\"Cluster {i}\" for i in cluster_means.index])\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Average Sales (millions)\")\n",
    "plt.title(\"Bar Chart: Average Regional Sales per Cluster\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec235f",
   "metadata": {
    "id": "62ec235f"
   },
   "source": [
    "\n",
    "## 7) Best Sellers by Console & Genre (Tables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6feed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a9a6feed",
    "outputId": "4f43c8a1-84cb-4183-fe5b-65cc0e0db36a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Best Sellers by Console & Genre (Full Tables) ---\n",
    "\n",
    "def top_n_by_group(df, group_col, value_col='Global_Sales', n=5, extra_cols=None):\n",
    "    \"\"\"Return top-n rows within each group (e.g., top 5 games per genre/platform).\"\"\"\n",
    "    if extra_cols is None:\n",
    "        extra_cols = []\n",
    "    frames = []\n",
    "    for g, sub in df.groupby(group_col):\n",
    "        cols = [c for c in ['Name', group_col, value_col] + extra_cols if c in sub.columns]\n",
    "        top_n = sub.sort_values(value_col, ascending=False).head(n)[cols]\n",
    "        top_n[group_col] = g\n",
    "        frames.append(top_n)\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# Top 5 games per Platform (shows ALL platforms)\n",
    "if 'Platform' in df.columns and 'Global_Sales' in df.columns:\n",
    "    top5_platform = top_n_by_group(df, 'Platform', 'Global_Sales', n=5, extra_cols=['Genre','Publisher'])\n",
    "    print(f\"Total Platforms: {df['Platform'].nunique()}\")\n",
    "    display(top5_platform.sort_values(['Platform', 'Global_Sales'], ascending=[True, False]))\n",
    "\n",
    "# Top 5 games per Genre (shows ALL genres)\n",
    "if 'Genre' in df.columns and 'Global_Sales' in df.columns:\n",
    "    top5_genre = top_n_by_group(df, 'Genre', 'Global_Sales', n=5, extra_cols=['Platform','Publisher'])\n",
    "    top5_genre[top5_genre['Genre'].isin(['Action', 'Sports', 'Shooter' 'Role-Playing', 'Platform'])]\n",
    "    print(f\"Total Genres: {df['Genre'].nunique()}\")\n",
    "    display(top5_genre.sort_values(['Genre', 'Global_Sales'], ascending=[True, False]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b2945",
   "metadata": {
    "id": "3c7b2945"
   },
   "source": [
    "\n",
    "## 8) Insights & Recommendations\n",
    "- **Genre dominance:** Action, Sports, and Shooter genres dominate.\n",
    "- **Platform dominance:** Nintendo and Playstation consoldes lead globally.\n",
    "- **Regional patterns (clusters):** North America dominates global game revenue in every cluster. Global blockbusters (Cluster 1) drive most sales. Smaller clusters show niche or regional opportunities. Japan focused games remain culturally strong but limited in volume.\n",
    "- **Actionable guidance:** Prioritize NA/EU marketing and release windows for maximum ROI. Support indie and niche generes through targeted digital campaigns. Invest in cross platform franchises to reach global audiences. Localize more effetively for Japan and emerging regions to expand cluster reach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee17edca",
   "metadata": {
    "id": "ee17edca"
   },
   "source": [
    "\n",
    "## 9) Conclusion\n",
    "- Data Driven segmentation uncovers clear market tiers in the video game industry.\n",
    "- Global blockbusers dominate revenue, but niche markets offer growth potential.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
